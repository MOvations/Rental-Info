{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CraigslistRentalInfo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MOvations/files/blob/master/CraigslistRentalInfo.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Co-eObzxYS_p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# %%capture\n",
        "# !pip install appdirs\n",
        "# !pip install inquirer\n",
        "# !pip install requests_cache"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eAwUBqh6X0Va",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"Display Craigslist rental market statistics\"\"\"\n",
        "\n",
        "# standard imports\n",
        "import argparse\n",
        "import os\n",
        "import re\n",
        "import statistics\n",
        "import sys\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from datetime import timedelta\n",
        "from textwrap import dedent\n",
        "\n",
        "# external imports\n",
        "import appdirs\n",
        "import inquirer\n",
        "import requests\n",
        "import requests_cache\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "# pylint: disable=too-few-public-methods, too-many-instance-attributes\n",
        "class Craigslist:\n",
        "    \"\"\"Scrape Craigslist listings and display resulting statistics\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # default values\n",
        "        self.minprice = 100\n",
        "        self.maxprice = 30000\n",
        "        self.url = 'https://austin.craigslist.org'\n",
        "\n",
        "        # query values\n",
        "        self.site = None\n",
        "        self.region = None\n",
        "        self.neighborhood = None\n",
        "        self.bedrooms = None\n",
        "        self.search = 'apa'\n",
        "\n",
        "        # result values\n",
        "        self.duration = 0\n",
        "        self.prices = []\n",
        "\n",
        "    def _getneighborhoods(self):\n",
        "        \"\"\"Return dictionary of neighborhoods for given site and region.\"\"\"\n",
        "\n",
        "        url = join(self.site, 'search', self.region, self.search)\n",
        "\n",
        "        soup = getsoup(url)\n",
        "\n",
        "        return {tag.next.strip(): tag.get('value') for tag\n",
        "                in soup.select('input[name=nh]')}\n",
        "\n",
        "    def _getprices(self):\n",
        "        \"\"\"Return list of prices for rental units.\"\"\"\n",
        "        base = join(self.site, 'search', self.region, self.search)\n",
        "\n",
        "        # pylint: disable=protected-access\n",
        "        encode_params = requests.models.RequestEncodingMixin._encode_params\n",
        "        params = encode_params({\n",
        "            'bedrooms': self.bedrooms,\n",
        "            'max_price': self.maxprice,\n",
        "            'min_price': self.minprice,\n",
        "            'nh': self.neighborhood\n",
        "        })\n",
        "\n",
        "        urlpattern = '{}?s=%d&{}'.format(base, params)\n",
        "\n",
        "        # create an iterator of all the URLs to query\n",
        "        urls = (urlpattern % i for i in range(0, 2500, 100))\n",
        "\n",
        "        # query pattern for prices of all n br rentals\n",
        "        pattern = r'(?<=<span class=\"price\">\\$)([0-9]*?)' \\\n",
        "                  r'(?=</span> <span class=\"housing\">/ %dbr )' % self.bedrooms\n",
        "\n",
        "        # query HTML for all 2500 rental market listings\n",
        "        html = concurrentdownload(urls)\n",
        "\n",
        "        # extract prices\n",
        "        strings = re.findall(pattern, html)\n",
        "\n",
        "        # convert list of strings into integers\n",
        "        prices = [int(i) for i in strings]\n",
        "\n",
        "        return prices\n",
        "\n",
        "    def _getregions(self):\n",
        "        \"\"\"Return default and dictionary of regions for given site.\"\"\"\n",
        "\n",
        "        url = join(self.site, 'search', self.search)\n",
        "        soup = getsoup(url)\n",
        "        tags = soup.select('#subArea > option')\n",
        "\n",
        "        try:\n",
        "            default = tags[0].text\n",
        "            regions = {tag.text: tag.get('value') for tag in tags[1:]}\n",
        "            return default, regions\n",
        "        except IndexError:\n",
        "            return None, {}\n",
        "\n",
        "    def _getsites(self):\n",
        "        \"\"\"Return dictionary of major US city sites.\"\"\"\n",
        "        soup = getsoup(self.url)\n",
        "\n",
        "        return {tag.text.replace('\\xa0', ' '): tag.get('href') for tag in\n",
        "                soup.find(text='us cities').next.select('li > a')[:-1]}\n",
        "\n",
        "    def _print(self):\n",
        "        \"\"\"Print statistics and other informational text.\"\"\"\n",
        "        mean = statistics.mean(self.prices)\n",
        "        median = statistics.median(self.prices)\n",
        "        stdev = statistics.stdev(self.prices)\n",
        "        high = mean + stdev\n",
        "        low = mean - stdev\n",
        "\n",
        "        print(dedent('''\\\n",
        "        Sourced %d prices in %.3f seconds\n",
        "\n",
        "        Mean:\\t$%.2f\n",
        "        Median:\\t$%.2f\n",
        "        Hi/Lo:\\t$%.2f/$%.2f\n",
        "        StDev:\\t%.2f\n",
        "        ''' % (len(self.prices), self.duration,\n",
        "               mean, median, high, low, stdev)))\n",
        "\n",
        "    def _query(self):\n",
        "        \"\"\"Query user for information.\"\"\"\n",
        "        sites = self._getsites()\n",
        "\n",
        "        results_site = prompt([\n",
        "            inquirer.List(\n",
        "                'site',\n",
        "                message='Which site?',\n",
        "                choices=sorted(\n",
        "                    sites,\n",
        "                    key=lambda x: '!' if x == 'austin' else x\n",
        "                )\n",
        "            )\n",
        "        ])['site']\n",
        "\n",
        "        self.site = sites[results_site]\n",
        "\n",
        "        # override NYC's funky apartment listings query\n",
        "        if results_site == 'new york':\n",
        "            self.search = 'aap'\n",
        "\n",
        "        default_region, regions = self._getregions()\n",
        "\n",
        "        if regions:\n",
        "            results_region = prompt([\n",
        "                inquirer.List(\n",
        "                    'region',\n",
        "                    message='Which region?',\n",
        "                    choices=[default_region] + sorted(\n",
        "                        regions,\n",
        "                        key=lambda x: x.lower()\n",
        "                    )\n",
        "                )\n",
        "            ])['region']\n",
        "\n",
        "            if results_region is not None:\n",
        "                self.region = regions.get(results_region)\n",
        "\n",
        "            if self.region is not None:\n",
        "                neighborhoods = self._getneighborhoods()\n",
        "                if neighborhoods:\n",
        "                    results_neighborhood = prompt([\n",
        "                        inquirer.List(\n",
        "                            'neighborhood',\n",
        "                            message='Which neighborhood?',\n",
        "                            choices=[None] + sorted(\n",
        "                                neighborhoods,\n",
        "                                key=lambda x: x.lower())\n",
        "                        )\n",
        "                    ])['neighborhood']\n",
        "\n",
        "                    if results_neighborhood is not None:\n",
        "                        self.neighborhood = neighborhoods[results_neighborhood]\n",
        "\n",
        "        results_bedrooms = prompt([\n",
        "            inquirer.List('bedrooms',\n",
        "                          message='How many bedrooms?',\n",
        "                          choices=['%dbr' % i for i in range(1, 7)])\n",
        "        ])['bedrooms']\n",
        "\n",
        "        self.bedrooms = int(results_bedrooms.rstrip('br'))\n",
        "\n",
        "    def run(self, cache=True):\n",
        "        \"\"\"Run application.\"\"\"\n",
        "\n",
        "        self._query()\n",
        "\n",
        "        # configure `requests` cache\n",
        "        if cache:\n",
        "            cache_dir = appdirs.user_cache_dir('craigslist')\n",
        "            os.makedirs(cache_dir, exist_ok=True)\n",
        "            requests_cache.install_cache(\n",
        "                cache_name=os.path.join(cache_dir, 'craigslist'),\n",
        "                expire_after=timedelta(hours=0.5))\n",
        "\n",
        "        print('Running query...\\n')\n",
        "\n",
        "        # record the start time\n",
        "        start = time.time()\n",
        "\n",
        "        self.prices = self._getprices()\n",
        "\n",
        "        # determine elapsed time of queries\n",
        "        self.duration = time.time() - start\n",
        "\n",
        "        # remove expired cache entries\n",
        "        if cache:\n",
        "            requests_cache.core.remove_expired_responses()\n",
        "\n",
        "        # print statistics (if any price data exists)\n",
        "        if self.prices:\n",
        "            self._print()\n",
        "        else:\n",
        "            print('Nothing found for that search.')\n",
        "\n",
        "\n",
        "def _parser(args):\n",
        "    \"\"\"Parse command-line options.\"\"\"\n",
        "\n",
        "    # pylint: disable=too-few-public-methods\n",
        "    class NegateAction(argparse.Action):\n",
        "        \"\"\"Support --toggle and --no-toggle options.\"\"\"\n",
        "\n",
        "        def __call__(self, parser, namespace, values, option_string=None):\n",
        "            setattr(namespace, self.dest, option_string[2:4] != 'no')\n",
        "\n",
        "    parser = argparse.ArgumentParser(\n",
        "        add_help=False,\n",
        "        description='Display Craigslist rental market statistics.',\n",
        "        usage='%(prog)s [OPTION]')\n",
        "    parser.add_argument(\n",
        "        '-h', '--help',\n",
        "        action='help',\n",
        "        help=argparse.SUPPRESS)\n",
        "    parser.add_argument(\n",
        "        '--cache', '--no-cache',\n",
        "        action=NegateAction,\n",
        "        default=True,\n",
        "        help='cache network queries (default)',\n",
        "        nargs=0)\n",
        "    parser.add_argument(\n",
        "        '--version',\n",
        "        action='version',\n",
        "        help=argparse.SUPPRESS,\n",
        "        version='%(prog)s 0.1.0')\n",
        "\n",
        "    return parser.parse_args(args).cache\n",
        "\n",
        "\n",
        "def concurrentdownload(urls):\n",
        "    \"\"\"Download URLs concurrently and return their HTML.\"\"\"\n",
        "    with ThreadPoolExecutor(max_workers=16) as executor:\n",
        "        return ''.join(executor.map(gethtml, urls))\n",
        "\n",
        "\n",
        "def gethtml(url):\n",
        "    \"\"\"Return the HTML for a given URL.\"\"\"\n",
        "    return requests.get(url).text\n",
        "\n",
        "\n",
        "def getsoup(url):\n",
        "    \"\"\"Return BeautifulSoup instance for given URL.\"\"\"\n",
        "    return BeautifulSoup(gethtml(url), 'html.parser')\n",
        "\n",
        "\n",
        "def join(base, *components):\n",
        "    \"\"\"Join two or more URL components, inserting '/' as needed.\"\"\"\n",
        "    sep = '/'\n",
        "    path = base\n",
        "    for item in components:\n",
        "        if item:\n",
        "            if not path or path.endswith(sep):\n",
        "                path += item\n",
        "            else:\n",
        "                path += sep + item\n",
        "    return path\n",
        "\n",
        "\n",
        "def main(args=None):\n",
        "    \"\"\"Start application.\"\"\"\n",
        "    cache = _parser(args)\n",
        "    craigslist = Craigslist()\n",
        "\n",
        "    try:\n",
        "        craigslist.run(cache=cache)\n",
        "    except KeyboardInterrupt:\n",
        "        print('Cancelled by user\\n', file=sys.stderr)\n",
        "        return 1\n",
        "\n",
        "\n",
        "def prompt(questions):\n",
        "    \"\"\"Adapted from inquirer.prompt so as to not suppress KeyboardInterrupt.\"\"\"\n",
        "    render = inquirer.render.console.ConsoleRender()\n",
        "    answers = {}\n",
        "\n",
        "    for question in questions:\n",
        "        answers[question.name] = render.render(question, answers)\n",
        "    return answers\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(main())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RwdXSrQXIUpq",
        "colab_type": "code",
        "outputId": "703aa4d3-4ced-4c17-e41f-8d7cc1f6f90d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-5f2c052fa97a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCraigslist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'Craigslist' has no attribute 'main'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "b3lyQMMkI04e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}